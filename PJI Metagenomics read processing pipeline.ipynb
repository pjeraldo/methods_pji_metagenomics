{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taxonomy analysis pipeline\n",
    "\n",
    "This is the set of steps used to call taxonomy assignments for metagenomic reads from prostethic join infection samples. These steps were executed for each sample used in the study.\n",
    "\n",
    "\n",
    "## Dependencies\n",
    "\n",
    "The processing pipeline uses the following software, along with their respective dependencies:\n",
    "\n",
    "* `samtools` v1.3, http://www.htslib.org/\n",
    "* `biobloomtools` v2.0.12, https://github.com/bcgsc/biobloom\n",
    "* `seqtk` latest, https://github.com/lh3/seqtk\n",
    "* `Trimmomatic` v0.35, http://www.usadellab.org/cms/?page=trimmomatic\n",
    "\n",
    "Specifically, for taxonomy assignment, we use\n",
    "\n",
    "* `LMAT` v1.2.6, https://computation.llnl.gov/projects/livermore-metagenomics-analysis-toolkit\n",
    "* `MetaPhlAn2` latest, https://bitbucket.org/biobakery/metaphlan2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "### Read clean-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAMPLE is the sample name\n",
    "SAMPLE=\"sample_name\"\n",
    "#NSLOTS is the number of CPUs to be used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract reads in fastq format from BAM files (our source files are BAM-formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samtools bam2fq -1 ${SAMPLE}_R1.fastq -2 ${SAMPLE}_R2.fastq /path/to/${SAMPLE}.bam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove sequencing adapters and basic removal of low-quality bases from each read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRIMMOMATIC_JAR is the location of the trimmomatic.jar files \n",
    "TRIMMOMATIC_JAR=/path/to/trimmomatic-0.35.jar\n",
    "#ADAPTERS is a trimmomatic-compatible file with sequencing adapters. Provided with Trimmomatic\n",
    "ADAPTERS=/path/to/trimmomatic-0.35/adapters.fasta\n",
    "\n",
    "java -jar $TRIMMOMATIC_JAR PE -threads $NSLOTS -phred33 \\\n",
    "${SAMPLE}_R1.fastq ${SAMPLE}_R2.fastq \\\n",
    "${SAMPLE}_R1.noadapter.fastq ${SAMPLE}_U1.noadapter.fastq \\\n",
    "${SAMPLE}_R2.noadapter.fastq ${SAMPLE}_U2.noadapter.fastq \\\n",
    "ILLUMINACLIP:$ADAPTERS:2:30:10 LEADING:3 TRAILING:3 MAXINFO:220:0.1 MINLEN:70\n",
    "\n",
    "#keep orphaned/unpaired reads together\n",
    "cat ${SAMPLE}_U[12].noadapter.fastq > ${SAMPLE}_U.noadapter.fastq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove human reads, stage 1 of 2\n",
    "\n",
    "`human.bf` and `phix.bf` are databases for `biobloomtools` created using the genomes of _Homo sapiens_ (hg19) and the _Enterobacteria phage ΦX174_, to remove human reads and leftover Illumina phiX control reads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HUMAN=/path/to/human.bf\n",
    "PHIX=/path/to/phix.bf\n",
    "#create working directory for biobloomtools output\n",
    "mkdir bloom\n",
    "\n",
    "#run biobloomtools\n",
    "biobloomcategorizer -t $NSLOTS -p bloom/$SAMPLE -f \"$HUMAN $PHIX\" --fq -e ${SAMPLE}_R1.noadapter.fastq ${SAMPLE}_R2.noadapter.fastq\n",
    "biobloomcategorizer -t $NSLOTS -p bloom/$SAMPLE -f \"$HUMAN $PHIX\" --fq ${SAMPLE}_U.noadapter.fastq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `LMAT` taxonomy analysis\n",
    "\n",
    "`LMATDB` and `LMATGENEDB` are databases for `LMAT` taxonomy call and gene call steps, respectively. Download them using the `LMAT`-provided scripts.\n",
    "\n",
    "`merge_fastq_reads_with_N_separator.pl`, `run_rl.sh` and `run_gl.sh` are provided with `LMAT`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set database locations\n",
    "LMATDB=/path/to/kML+Human.v4-14.20.g10.db\n",
    "LMATGENEDB=/path/to/lmat.genes.7-14.db\n",
    "\n",
    "#join paired reads in preparation for LMAT\n",
    "#mask bases with PHRED score lower than 10 using an N\n",
    "merge_fastq_reads_with_N_separator.pl bloom/${SAMPLE}_noMatch_1.fq bloom/${SAMPLE}_noMatch_2.fq /dev/stdout | \n",
    "seqtk seq -A -q 10 -n N > ${SAMPLE}_merged.fasta\n",
    "seqtk seq -A -q 10 -n N bloom/${SAMPLE}_noMatch.fq >> ${SAMPLE}_merged.fasta\n",
    "\n",
    "#${SAMPLE}_merged.fasta will be the input to LMAT\n",
    "#LMATOUT is the output directory for LMAT\n",
    "LMATOUT=lmat_output\n",
    "mkdir $LMATOUT\n",
    "run_rl2.sh --threads=$NSLOTS --query_file=${SAMPLE}_merged.fasta --db_file=$LMATDB --odir=$LMATOUT\n",
    "\n",
    "cd $LMATOUT\n",
    "\n",
    "#prepare for LMAT-genes\n",
    "\n",
    "FSUMM=$(ls *.fastsummary)\n",
    "ls *out > ${SAMPLE}_rl_out.txt\n",
    "run_gl.sh --threads=$NSLOTS --db_file=$LMATGENEDB --odir=. --ilst=${SAMPLE}_rl_out.txt --filesum=$FSUMM\n",
    "rm -v $LMATGENEDB\n",
    "GSUMM=$(ls *.genesummary)\n",
    "\n",
    "cd ..\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove human reads, stage 2 of 2\n",
    "Now that LMAT has executed fully, remove reads assigned to _Homo sapiens_.\n",
    "\n",
    "`remove_ids_from_fastq.py` is a custom script provided in this repository, which removes reads from a fastq file given a list of read IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "awk '{if ($(NF-2) == 9606 && $(NF) == \"DirectMatch\") print $1}' $LMATOUT/*.out > human.accnos\n",
    "\n",
    "remove_ids_from_fastq.py human.accnos -i bloom/${SAMPLE}_noMatch_1.fq -o ${SAMPLE}_R1.clean.fastq\n",
    "remove_ids_from_fastq.py human.accnos -i bloom/${SAMPLE}_noMatch_2.fq -o ${SAMPLE}_R2.clean.fastq\n",
    "remove_ids_from_fastq.py human.accnos -i bloom/${SAMPLE}_noMatch.fq -o ${SAMPLE}_U.clean.fastq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `MetaPhlAn2` taxonomy analysis\n",
    "`v20_m200` refers to the name of the default database for `MetaPhlAn2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metaphlan2.py --nproc $NSLOTS  -x v20_m200 \\\n",
    "--sample_id $SAMPLE -o $SAMPLE.metaphlan.txt --bowtie2out $SAMPLE.bowtie2.out \\\n",
    "--input_type fastq ${SAMPLE}_R1.clean.fastq,${SAMPLE}_R2.clean.fastq,${SAMPLE}_U.clean.fastq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outputs\n",
    "The output files are:\n",
    "* `$SAMPLE.metaphlan.txt` from `MetaPhlAn2` (and `$SAMPLE.bowtie2.out` for further exploration)\n",
    "* The `*.fastsummary` files inside the `$LMATOUT` directory. The `*.out` files can be used to verify hits, but they can take up a lot of space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copyright\n",
    "Copyright © 2018, Mayo Foundation for Medical Education and Research. All rights reserved."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
